library(tidyverse)
library(tidytext)
library(tidymodels)
library(textstem)
library(rvest)
library(qdapRegex)
library(stopwords)
library(tokenizers)
library(sparsesvd)
library(glmnet)
source("scripts/modified-preprocessing.R")
source("scripts/projection.R")
# load raw data
load('data/claims-raw.RData')
# clean raw data
claims_clean <- claims_raw %>%
parse_data()
# clean raw data
claims_clean <- claims_raw %>%
parse_data()
claims <- claims_clean %>%
nlp_fn()
claims <- claims_clean %>%
nlp_fn()
set.seed(11182024)
# partition claims data
partitions <- claims %>% initial_split(prop = 0.8)
test_dtm <- testing(partitions) %>%
select(-.id, -bclass, -mclass) %>%
as.matrix()
test_labels <- testing(partitions) %>%
select(.id, bclass, mclass)
test_id <- test_labels %>% pull(.id)
save(test_id, file = "data/test-id.RData")
train_dtm <- training(partitions) %>%
select(-.id, -bclass, -mclass) %>%
as.matrix()
train_labels <- training(partitions) %>%
select(.id, bclass, mclass)
train_id <- train_labels %>% pull(.id)
save(train_id, file = "data/train-id.RData")
proj_out <- projection_fn(train_dtm, 0.7)
train_dtm_projected <- proj_out$data
train <- train_labels %>%
transmute(bclass = factor(bclass)) %>%
bind_cols(train_dtm_projected)
x_train <- train %>% select(-bclass) %>% as.matrix()
y_train <- train_labels %>% pull(bclass)
alpha_enet <- 0.3
fit_reg <- glmnet(x = x_train,
y = y_train,
family = 'binomial',
alpha = alpha_enet)
cvout <- cv.glmnet(x = x_train,
y = y_train,
family = 'binomial',
alpha = alpha_enet)
# store optimal strength
lambda_opt <- cvout$lambda.min
train_log_odds <- predict(fit_reg,
s = lambda_opt,
newx = x_train,
type = "link")
save(train_log_odds, file = "data/train-log-odds.RData")
# project test data onto PCs
test_dtm_projected <- reproject_fn(.dtm = test_dtm, proj_out)
# coerce to matrix
x_test <- as.matrix(test_dtm_projected)
preds <- predict(fit_reg,
s = lambda_opt,
newx = x_test,
type = 'response')
test_log_odds <- predict(fit_reg,
s = lambda_opt,
newx = x_test,
type = "link")
save(test_log_odds, file = "data/test-log-odds.RData")
pred_df <- test_labels %>%
transmute(bclass = factor(bclass)) %>%
bind_cols(pred = as.numeric(preds)) %>%
mutate(bclass.pred = factor(pred > 0.5,
labels = levels(bclass)))
panel <- metric_set(sensitivity,
specificity,
accuracy,
roc_auc)
pred_df %>% panel(truth = bclass,
estimate = bclass.pred,
pred,
event_level = 'second')
require(tidyverse)
require(keras)
require(tensorflow)
load('data/claims-test.RData')
load('data/claims-raw.RData')
source('scripts/preprocessing.R')
tf_model <- load_model_tf('results/example-model')
clean_df <- claims_test %>%
slice(1:100) %>%
parse_data() %>%
select(.id, text_clean)
x <- clean_df %>%
pull(text_clean)
preds <- predict(tf_model, x) %>%
as.numeric()
class_labels <- claims_raw %>% pull(bclass) %>% levels()
pred_classes <- factor(preds > 0.5, labels = class_labels)
pred_df <- clean_df %>%
bind_cols(bclass.pred = pred_classes) %>%
select(.id, bclass.pred)
tf_model <- load_model_tf('results/example-model')
# can comment entire section out if no changes to preprocessing.R
source('scripts/preprocessing.R')
# load raw data
load('data/claims-raw.RData')
claims_clean <- claims_raw %>%
parse_data()
# export
save(claims_clean, file = 'data/claims-clean-example.RData')
library(tidyverse)
library(tidymodels)
library(keras)
library(tensorflow)
# load cleaned data
load('data/claims-clean-example.RData')
set.seed(110122)
partitions <- claims_clean %>%
initial_split(prop = 0.8)
train_text <- training(partitions) %>%
pull(text_clean)
train_labels <- training(partitions) %>%
pull(bclass) %>%
as.numeric() - 1
preprocess_layer <- layer_text_vectorization(
standardize = NULL,
split = 'whitespace',
ngrams = NULL,
max_tokens = NULL,
output_mode = 'tf_idf'
)
preprocess_layer %>% adapt(train_text)
model <- keras_model_sequential() %>%
preprocess_layer() %>%
layer_dropout(0.2) %>%
layer_dense(units = 25) %>%
layer_dropout(0.2) %>%
layer_dense(1) %>%
layer_activation(activation = 'sigmoid')
summary(model)
model %>% compile(
loss = 'binary_crossentropy',
optimizer = 'adam',
metrics = 'binary_accuracy'
)
history <- model %>%
fit(train_text,
train_labels,
validation_split = 0.3,
epochs = 5)
test_text <- testing(partitions) %>%
pull(text_clean)
test_labels <- testing(partitions) %>%
pull(bclass) %>%
as.numeric() - 1
evaluate(model, test_text, test_labels)
evaluate(model, test_text, test_labels)
true_labels <- claims_test %>%
pull(bclass)
evaluate(model, test_text, test_labels)
load('results/example-preds.RData')
true_labels <- claims_test %>%
pull(bclass)
# save the entire model as a SavedModel
save_model_tf(model, "results/example-model")
panel <- metric_set(sensitivity,
specificity,
accuracy,
roc_auc)
pred_df %>% panel(truth = bclass,
estimate = bclass.pred,
pred,
event_level = 'second')
pred_df <- clean_df %>%
bind_cols(bclass.pred = pred_classes) %>%
select(.id, bclass.pred)
# compute predictions
preds <- predict(tf_model, x) %>%
as.numeric()
tf_model <- load_model_tf('results/example-model')
preds <- predict(tf_model, x) %>%
as.numeric()
class_labels <- claims_raw %>% pull(bclass) %>% levels()
pred_classes <- factor(preds > 0.5, labels = class_labels)
pred_df <- clean_df %>%
bind_cols(bclass.pred = pred_classes) %>%
select(.id, bclass.pred)
save(pred_df, file = 'results/example-preds.RData')
panel <- metric_set(sensitivity,
specificity,
accuracy,
roc_auc)
pred_df %>% panel(truth = bclass,
estimate = bclass.pred,
pred,
event_level = 'second')
pred_df
with_labels <- pred_df %>%
transmute(bclass = factor(bclass)) %>%
bind_cols(pred = as.numeric(preds)) %>%
mutate(bclass.pred = factor(pred > 0.5,
labels = levels(bclass)))
pred_classes
# Predictions and accuracy with just paragraphs
source("scripts/prediction.R")
load(pred_df, file = 'results/example-preds.RData')
load(pred_df, file = 'results/example-preds.RData')
load('results/example-preds.RData')
pred_df
class_labels
pred_df <- clean_df %>%
bind_cols(bclass.pred = pred_classes)
pred_df
colnames(pred_df)
clean_df
claims_test
test_labels
partitions
testing(partitions)
test_labels
test_labels <- testing(partitions) %>%
select(.id, bclass, mclass)
test_labels
pred_df <- test_labels %>%
transmute(bclass = factor(bclass)) %>%
bind_cols(pred = as.numeric(preds)) %>%
mutate(bclass.pred = factor(pred > 0.5,
labels = levels(bclass)))
source("scripts/modified-preprocessing.R")
source("scripts/projection.R")
# load raw data
load('data/claims-raw.RData')
# clean raw data
claims_clean <- claims_raw %>%
parse_data()
claims <- claims_clean %>%
nlp_fn()
set.seed(11182024)
# partition claims data
partitions <- claims %>% initial_split(prop = 0.8)
# separate DTM from labels
test_dtm <- testing(partitions) %>%
select(-.id, -bclass, -mclass) %>%
as.matrix()
test_labels <- testing(partitions) %>%
select(.id, bclass, mclass)
test_id <- test_labels %>% pull(.id)
save(test_id, file = "data/test-id.RData")
# same, training set
train_dtm <- training(partitions) %>%
select(-.id, -bclass, -mclass) %>%
as.matrix()
train_labels <- training(partitions) %>%
select(.id, bclass, mclass)
train_id <- train_labels %>% pull(.id)
save(train_id, file = "data/train-id.RData")
# PCA/projection
proj_out <- projection_fn(train_dtm, 0.7)
train_dtm_projected <- proj_out$data
# Fit Regression
train <- train_labels %>%
transmute(bclass = factor(bclass)) %>%
bind_cols(train_dtm_projected)
# store predictors and response as matrix and vector
x_train <- train %>% select(-bclass) %>% as.matrix()
y_train <- train_labels %>% pull(bclass)
# fit enet model
alpha_enet <- 0.3
fit_reg <- glmnet(x = x_train,
y = y_train,
family = 'binomial',
alpha = alpha_enet)
# choose a constraint strength by cross-validation
cvout <- cv.glmnet(x = x_train,
y = y_train,
family = 'binomial',
alpha = alpha_enet)
# store optimal strength
lambda_opt <- cvout$lambda.min
# get log-odds
train_log_odds <- predict(fit_reg,
s = lambda_opt,
newx = x_train,
type = "link")
save(train_log_odds, file = "data/train-log-odds.RData")
# project test data onto PCs
test_dtm_projected <- reproject_fn(.dtm = test_dtm, proj_out)
# coerce to matrix
x_test <- as.matrix(test_dtm_projected)
# compute predicted probabilities
preds <- predict(fit_reg,
s = lambda_opt,
newx = x_test,
type = 'response')
# get log-odds
test_log_odds <- predict(fit_reg,
s = lambda_opt,
newx = x_test,
type = "link")
save(test_log_odds, file = "data/test-log-odds.RData")
# store predictions in a data frame with true labels
pred_df <- test_labels %>%
transmute(bclass = factor(bclass)) %>%
bind_cols(pred = as.numeric(preds)) %>%
mutate(bclass.pred = factor(pred > 0.5,
labels = levels(bclass)))
# define classification metric panel
panel <- metric_set(sensitivity,
specificity,
accuracy,
roc_auc)
# compute test set accuracy
pred_df %>% panel(truth = bclass,
estimate = bclass.pred,
pred,
event_level = 'second')
load('data/test-id.RData')
test-id
test_id
load('data/claims-raw.RData')
save(test_labels, file = "data/test-labels.RData")
load('data/test-labels.RData')
test_labels
with_labels <- clean_df %>%
bind_cols(bclass.pred = pred_classes) %>%
inner_join(test_labels, by = ".id")
with_labels
test_labels_2 <- claims_raw %>%
filter(.id %in% test_id) %>%
select(.id, bclass)
with_labels <- clean_df %>%
bind_cols(bclass.pred = pred_classes) %>%
inner_join(test_labels_2, by = ".id")
with_labels
clean_df <- claims_test %>%
slice(1:100)
clean_df
source("scripts/preprocessing.R")
source("scripts/projection.R")
# load raw data
load('data/claims-raw.RData')
claims_clean_p <- claims_raw %>%
parse_data()
claims_p <- claims_clean_p %>%
nlp_fn()
partitions_p <- claims_p %>% initial_split(prop = 0.8)
# separate DTM from labels
test_dtm_p <- testing(partitions_p) %>%
select(-.id, -bclass, -mclass) %>%
as.matrix()
test_dtm_p <- testing(partitions_p) %>%
select(-.id, -bclass, -mclass) %>%
as.matrix()
testing(partitions_p)
test_dtm_p <- testing(partitions_p) %>%
select(-.id, -bclass) %>%
as.matrix()
test_labels_p <- testing(partitions_p) %>%
select(.id, bclass)
test_id_p <- test_labels_p %>% pull(.id)
train_dtm_p <- training(partitions_p) %>%
select(-.id, -bclass) %>%
as.matrix()
train_labels_p <- training(partitions_p) %>%
select(.id, bclass)
train_id_p <- train_labels_p %>% pull(.id)
proj_out_p <- projection_fn(train_dtm_p, 0.7)
train_dtm_projected_p <- proj_out_p$data
train_p <- train_labels_p %>%
transmute(bclass = factor(bclass)) %>%
bind_cols(train_dtm_projected_p)
x_train_p <- train_p %>% select(-bclass) %>% as.matrix()
y_train_p <- train_labels_p %>% pull(bclass)
alpha_enet <- 0.3
fit_reg_p <- glmnet(x = x_train_p,
y = y_train_p,
family = 'binomial',
alpha = alpha_enet)
# choose a constraint strength by cross-validation
cvout_p <- cv.glmnet(x = x_train_p,
y = y_train_p,
family = 'binomial',
alpha = alpha_enet)
# store optimal strength
lambda_opt_p <- cvout_p$lambda.min
train_log_odds_p <- predict(fit_reg_p,
s = lambda_opt,
newx = x_train_p,
type = "link")
# project test data onto PCs
test_dtm_projected_p <- reproject_fn(.dtm = test_dtm_p, proj_out_p)
# coerce to matrix
x_test_p <- as.matrix(test_dtm_projected_p)
preds_p <- predict(fit_reg_p,
s = lambda_opt,
newx = x_test_p,
type = 'response')
test_log_odds_p <- predict(fit_reg_p,
s = lambda_opt,
newx = x_test_p,
type = "link")
pred_df_p <- test_labels_p %>%
transmute(bclass = factor(bclass)) %>%
bind_cols(pred = as.numeric(preds_p)) %>%
mutate(bclass.pred = factor(pred > 0.5,
labels = levels(bclass)))
panel <- metric_set(sensitivity,
specificity,
accuracy,
roc_auc)
pred_df_p %>% panel(truth = bclass,
estimate = bclass.pred,
pred,
event_level = 'second')
